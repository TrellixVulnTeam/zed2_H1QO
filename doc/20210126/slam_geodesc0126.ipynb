{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "slam_geodesc0125.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4hfsu4n31nq"
      },
      "source": [
        "#drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-eJWUnKTKut"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vhsVphU332R",
        "outputId": "403e71f6-f32b-4f76-c463-f9de1bc0a206"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "#ai lab jp"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr-0CgjhTMU8"
      },
      "source": [
        "#geodesc.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1ehbZVCsT4U"
      },
      "source": [
        "#contextdesc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hSpQ7_jsVrc"
      },
      "source": [
        "## 環境構築"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpaekZomsRfQ"
      },
      "source": [
        "!pip uninstall -y tensorflow-gpu\r\n",
        "!pip uninstall -y tensorflow\r\n",
        "!pip install tensorflow-gpu==1.14.0\r\n",
        "!pip install tensorflow==1.14.0\r\n",
        "!pip uninstall  -y opencv-contrib-python\r\n",
        "!pip uninstall -y  opencv-python\r\n",
        "!pip install opencv-python==3.4.2.17\r\n",
        "!pip install opencv-contrib-python==3.4.2.17\r\n",
        "!pip install open3d==0.10\r\n",
        "# !rm -rf /usr/local/lib/python3.6/dist-packages/cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGyWKaphD1Nw",
        "outputId": "7e6d8e27-9bdb-4ba5-b9b2-b29f8b8fc280"
      },
      "source": [
        "# !pip uninstall -y open3d-python"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping open3d-python as it is not installed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i0UdNAcDDnE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdcx1BqCsou4"
      },
      "source": [
        "## ソースダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDob_sjOkySZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18c53fbc-9c23-48d6-90bb-c080bfa68d9d"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/00_work/004_pose_estimation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EpUSsi5sx0c"
      },
      "source": [
        "# !git clone https://github.com/lzx551402/contextdesc.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5Ellgvdsy2C"
      },
      "source": [
        "##訓練済みモデルダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ced3XKfV18_"
      },
      "source": [
        "# !mkdir {bp}/contextdesc/pretrained\r\n",
        "# %cd {bp}/contextdesc/pretrained\r\n",
        "# !wget https://research.altizure.com/data/contextdesc_models/contextdesc_pp.tar\r\n",
        "# !tar -xvf contextdesc_pp.tar\r\n",
        "# !wget https://research.altizure.com/data/contextdesc_models/retrieval_model.tar\r\n",
        "# !tar -xvf retrieval_model.tar\r\n",
        "# !wget https://research.altizure.com/data/contextdesc_models/dense-contextdesc.tar\r\n",
        "# !tar -xvf dense-contextdesc.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qmua7_qX0UE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "602e81f2-35c0-40b9-f48b-ed20abe1df86"
      },
      "source": [
        "\r\n",
        "bp='/content/drive/MyDrive/00_work/004_pose_estimation/'\r\n",
        "%cd {bp}\r\n",
        "%cd {bp}/contextdesc\r\n",
        "# !python image_matching.py \r\n",
        "  # --loc_model '/content/contextdesc/pretrained/dense-contextdesc'\r\n",
        "# --reg_model 'pretrained/contextdesc++'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/00_work/004_pose_estimation\n",
            "/content/drive/MyDrive/00_work/004_pose_estimation/contextdesc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjJoreJzEj0Q"
      },
      "source": [
        "## 特徴取得"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sPRVN2vqk5a"
      },
      "source": [
        "#!/usr/bin/env python3\r\n",
        "import sys\r\n",
        "%cd {bp}/contextdesc\r\n",
        "LOCAL_PATH = '../'\r\n",
        "if LOCAL_PATH not in sys.path:\r\n",
        "    sys.path.append(LOCAL_PATH)\r\n",
        "import os\r\n",
        "! echo $PYTHONPATH\r\n",
        "os.environ['PYTHONPATH'] = '/env/python:{bp}/contextdesc/'\r\n",
        "from models import get_model\r\n",
        "from models.reg_model import RegModel\r\n",
        "UTILS_PATH=\"{bp}/contextdesc/\"\r\n",
        "if UTILS_PATH not in sys.path:\r\n",
        "    sys.path.append(UTILS_PATH)\r\n",
        "# get_model('reg_model')\r\n",
        "import os\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "UTILS_PATH = 'utils'\r\n",
        "if UTILS_PATH not in sys.path:\r\n",
        "    sys.path.append(UTILS_PATH)\r\n",
        "from opencvhelper import MatcherWrapper\r\n",
        "\r\n",
        "from easydict import EasyDict\r\n",
        "\r\n",
        "UTILS_PATH = '../models'\r\n",
        "if UTILS_PATH not in sys.path:\r\n",
        "    sys.path.append(UTILS_PATH)\r\n",
        "from models import get_model\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "FLAGS = EasyDict({})\r\n",
        "FLAGS.loc_model='pretrained/contextdesc++'\r\n",
        "FLAGS.reg_model='pretrained/retrieval_model'\r\n",
        "FLAGS.img1_path='imgs/rgb_cam0.png'\r\n",
        "FLAGS.img2_path='imgs/rgb_cam1.png'\r\n",
        "FLAGS.n_sample=2048\r\n",
        "FLAGS.model_type='pb'\r\n",
        "FLAGS.dense_desc=False\r\n",
        "FLAGS.ratio_test=False\r\n",
        "FLAGS.cross_check=False\r\n",
        "\r\n",
        "\r\n",
        "def load_imgs(img_paths):\r\n",
        "    rgb_list = []\r\n",
        "    gray_list = []\r\n",
        "    for img_path in img_paths:\r\n",
        "        img = cv2.imread(img_path)\r\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)[..., np.newaxis]\r\n",
        "        img = img[..., ::-1]\r\n",
        "        rgb_list.append(img)\r\n",
        "        gray_list.append(gray)\r\n",
        "    return rgb_list, gray_list\r\n",
        "\r\n",
        "\r\n",
        "def extract_regional_features(rgb_list, model_path):\r\n",
        "    reg_feat_list = []\r\n",
        "    model = get_model('reg_model')(model_path)\r\n",
        "    for _, val in enumerate(rgb_list):\r\n",
        "        reg_feat = model.run_test_data(val)\r\n",
        "        reg_feat_list.append(reg_feat)\r\n",
        "    model.close()\r\n",
        "    return reg_feat_list\r\n",
        "\r\n",
        "\r\n",
        "def extract_local_features(gray_list, model_path):\r\n",
        "    cv_kpts_list = []\r\n",
        "    loc_info_list = []\r\n",
        "    loc_feat_list = []\r\n",
        "    sift_feat_list = []\r\n",
        "    model = get_model('loc_model')(model_path, **{'sift_desc': True,\r\n",
        "                                                  'n_sample': FLAGS.n_sample,\r\n",
        "                                                  'peak_thld': 0.04,\r\n",
        "                                                  'dense_desc': FLAGS.dense_desc,\r\n",
        "                                                  'upright': False})\r\n",
        "    for _, val in enumerate(gray_list):\r\n",
        "        loc_feat, kpt_mb, normalized_xy, cv_kpts, sift_desc = model.run_test_data(val)\r\n",
        "        raw_kpts = [np.array((i.pt[0], i.pt[1], i.size, i.angle, i.response)) for i in cv_kpts]\r\n",
        "        raw_kpts = np.stack(raw_kpts, axis=0)\r\n",
        "        loc_info = np.concatenate((raw_kpts, normalized_xy, loc_feat, kpt_mb), axis=-1)\r\n",
        "        cv_kpts_list.append(cv_kpts)\r\n",
        "        loc_info_list.append(loc_info)\r\n",
        "        sift_feat_list.append(sift_desc)\r\n",
        "        loc_feat_list.append(loc_feat / np.linalg.norm(loc_feat, axis=-1, keepdims=True))\r\n",
        "    model.close()\r\n",
        "    return cv_kpts_list, loc_info_list, loc_feat_list, sift_feat_list\r\n",
        "\r\n",
        "\r\n",
        "def extract_augmented_features(reg_feat_list, loc_info_list, model_path):\r\n",
        "    aug_feat_list = []\r\n",
        "    model = get_model('aug_model')(model_path, **{'quantz': False})\r\n",
        "    assert len(reg_feat_list) == len(loc_info_list)\r\n",
        "    for idx, _ in enumerate(reg_feat_list):\r\n",
        "        aug_feat, _ = model.run_test_data([reg_feat_list[idx], loc_info_list[idx]])\r\n",
        "        aug_feat_list.append(aug_feat)\r\n",
        "    model.close()\r\n",
        "    return aug_feat_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv5I7Pj2QjfO"
      },
      "source": [
        "cam_zed2_22378008_left_hd1080 = EasyDict({})\r\n",
        "cam_zed2_22378008_left_hd1080.fx=1055.26\r\n",
        "cam_zed2_22378008_left_hd1080.fy=1054.92\r\n",
        "cam_zed2_22378008_left_hd1080.cx=962.91\r\n",
        "cam_zed2_22378008_left_hd1080.cy=567.182\r\n",
        "cam_zed2_22378008_left_hd1080.depthScale=1000.0\r\n",
        "\r\n",
        "'''\r\n",
        "\r\n",
        "      \"fx\": 1058.51,\r\n",
        "      \"fy\": 1057.56,\r\n",
        "      \"cx\": 972.89,\r\n",
        "      \"cy\": 570.658,\r\n",
        "'''\r\n",
        "cam_zed2_21888201_left_hd1080 = EasyDict({})\r\n",
        "cam_zed2_21888201_left_hd1080.fx=1058.51\r\n",
        "cam_zed2_21888201_left_hd1080.fy=1057.56\r\n",
        "cam_zed2_21888201_left_hd1080.cx=972.89\r\n",
        "cam_zed2_21888201_left_hd1080.cy=570.658\r\n",
        "cam_zed2_21888201_left_hd1080.depthScale=1000.0\r\n",
        "\r\n",
        "'''\r\n",
        "\r\n",
        "   \"StereoLabs_ZED2_22115402_LEFT_HD1080\": {\r\n",
        "      \"fx\": 1058.82,\r\n",
        "      \"fy\": 1058.16,\r\n",
        "      \"cx\": 909.73,\r\n",
        "      \"cy\": 560.099,\r\n",
        "'''\r\n",
        "cam_zed2_22115402_left_hd1080 = EasyDict({})\r\n",
        "cam_zed2_22115402_left_hd1080.fx=1058.82\r\n",
        "cam_zed2_22115402_left_hd1080.fy=1058.16\r\n",
        "cam_zed2_22115402_left_hd1080.cx=909.73\r\n",
        "cam_zed2_22115402_left_hd1080.cy=560.099\r\n",
        "cam_zed2_22115402_left_hd1080.depthScale=1000.0\r\n",
        "\r\n",
        "bp='/content/drive/MyDrive/00_work/004_pose_estimation/contextdesc/imgs/'\r\n",
        "\r\n",
        "imgdic = EasyDict({})\r\n",
        "imgdic.rgb0=cv2.imread(f\"{bp}/rgb_cam0.png\")\r\n",
        "imgdic.rgb1=cv2.imread(f\"{bp}/rgb_cam1.png\")\r\n",
        "imgdic.rgb2=cv2.imread(f\"{bp}/rgb_cam2.png\")\r\n",
        "imgdic.dpt0=np.load(f\"{bp}/depth_cam0.npy\")\r\n",
        "imgdic.dpt1=np.load(f\"{bp}/depth_cam1.npy\")\r\n",
        "imgdic.dpt2=np.load(f\"{bp}/depth_cam2.npy\")\r\n",
        "imgdic.pcd0=np.load(f\"{bp}/pcd_cam0.npy\")\r\n",
        "imgdic.pcd1=np.load(f\"{bp}/pcd_cam1.npy\")\r\n",
        "imgdic.pcd2=np.load(f\"{bp}/pcd_cam2.npy\")\r\n",
        "'''\r\n",
        "cam_zed2_21888201_left_hd1080:cam0\r\n",
        "cam_zed2_22378008_left_hd1080:cam1\r\n",
        "cam_zed2_22115402_left_hd1080:cam2\r\n",
        "get_good_matches_pts(goodMatches,kp1,kp2,imgdic,cams_para)\r\n",
        "'''\r\n",
        "cams_para=[cam_zed2_21888201_left_hd1080,cam_zed2_22378008_left_hd1080,cam_zed2_22115402_left_hd1080]\r\n",
        "def get_good_matches_pts(goodMatches,kp1,kp2,imgdic,cams):\r\n",
        "    pts_obj1=[]\r\n",
        "    pts_obj2=[]\r\n",
        "    pts_img1=[]\r\n",
        "    pts_img2=[]\r\n",
        "    def make_obj(p,d,cam):\r\n",
        "        pt=[p[1],p[0],d]\r\n",
        "        pd= point2dTo3d(pt,cam)\r\n",
        "        return pd\r\n",
        "    for i, goodMatch in enumerate(goodMatches):\r\n",
        "        p1=np.array(kp1[goodMatch.queryIdx].pt,dtype=np.int)\r\n",
        "        p2=np.array(kp2[goodMatch.trainIdx].pt,dtype=np.int)\r\n",
        "        d1=imgdic.dpt0[p1[1],p1[0]]\r\n",
        "        d2=imgdic.dpt1[p2[1],p2[0]]\r\n",
        "        if d1 == 0 or d2 == 0 :\r\n",
        "            continue;\r\n",
        "        pts1=make_obj(p1, d1,cams[0])\r\n",
        "        pts2=make_obj(p2,d2,cams[1])\r\n",
        "        if np.isnan(np.mean(pts1))  or np.isnan(np.mean(pts2)) or np.isinf(np.mean(pts1)) or np.isinf(np.mean(pts2)):\r\n",
        "            continue\r\n",
        "        pts_obj1.append(pts1)\r\n",
        "        pts_obj2.append(pts2)\r\n",
        "        pts_img1.append(p1)\r\n",
        "        pts_img2.append(p2)\r\n",
        "\r\n",
        "    if len(pts_obj1)==0 or len(pts_img2)==0:\r\n",
        "        return -1\r\n",
        "    print(f\"pts_obj1:{len(pts_obj1)},pts_obj2:{len(pts_obj2)}\")\r\n",
        "    id=0\r\n",
        "    cameraMatrix1=[\r\n",
        "        [cams[id].fx,0,cams[id].cx],\r\n",
        "        [0,cams[id].fy,cams[id].cy],\r\n",
        "        [0,0,1]\r\n",
        "        ]\r\n",
        "    id=1\r\n",
        "    cameraMatrix2=[\r\n",
        "        [cams[id].fx,0,cams[id].cx],\r\n",
        "        [0,cams[id].fy,cams[id].cy],\r\n",
        "        [0,0,1]\r\n",
        "        ]\r\n",
        "    distCoeffs=[0, 0, 0, 0, 0]\r\n",
        "    pts_img1=np.array(pts_img1,dtype=np.float32)\r\n",
        "    pts_img2=np.array(pts_img2,dtype=np.float32)\r\n",
        "    pts_obj1 = np.array(pts_obj1, dtype=np.float32)\r\n",
        "    pts_obj2 = np.array(pts_obj2, dtype=np.float32)\r\n",
        "    cameraMatrix1 = np.array(cameraMatrix1, dtype=np.float64)\r\n",
        "    cameraMatrix2 = np.array(cameraMatrix2, dtype=np.float64)\r\n",
        "    distCoeffs = np.array(distCoeffs, dtype=np.float64)\r\n",
        "\r\n",
        "    _, rVec1, tVec1=cv2.solvePnP(pts_obj1, pts_img1, cameraMatrix1, distCoeffs=distCoeffs)\r\n",
        "    _, rVec2, tVec2=cv2.solvePnP(pts_obj2, pts_img2, cameraMatrix2, distCoeffs=distCoeffs)\r\n",
        "    R1=cv2.Rodrigues(rVec1)[0]\r\n",
        "    R2=cv2.Rodrigues(rVec2)[0]\r\n",
        "    R_12 = R2 @ R1.T\r\n",
        "    # t_12= R2 @ (-R1.T @ tVec1) + tVec2\r\n",
        "    t_12= tVec2 - R_12@tVec1\r\n",
        "    # trans12=generateTransMatrixRt(t_12,R_12)\r\n",
        "    trans12 = np.eye(4)\r\n",
        "    trans12[:3, :3] = R_12\r\n",
        "    trans12[:3, 3] = t_12.flatten()\r\n",
        "    return trans12,pts_obj1,pts_obj2\r\n",
        "\r\n",
        "def get_key_points(goodMatches,kp1,kp2,imgdic):\r\n",
        "    pts_obj1=[]\r\n",
        "    pts_obj2=[]\r\n",
        "    for i, goodMatch in enumerate(goodMatches):\r\n",
        "        p1=np.array(kp1[goodMatch.queryIdx].pt,dtype=np.int)\r\n",
        "        p2=np.array(kp2[goodMatch.trainIdx].pt,dtype=np.int)\r\n",
        "        pts1=imgdic.pcd0[p1[1],p1[0]]\r\n",
        "        pts2=imgdic.pcd1[p2[1],p2[0]]\r\n",
        "        if np.isnan(np.mean(pts1))  or np.isnan(np.mean(pts2)) or np.isinf(np.mean(pts1)) or np.isinf(np.mean(pts2)):\r\n",
        "            continue\r\n",
        "        pts_obj1.append(pts1[:3])\r\n",
        "        pts_obj2.append(pts2[:3])\r\n",
        "    return np.array(pts_obj1),np.array(pts_obj2)\r\n",
        "def get_key_ply(goodMatches,kp1,kp2,imgdic):\r\n",
        "    pts_obj1=[]\r\n",
        "    pts_obj2=[]\r\n",
        "    cols1=[]\r\n",
        "    cols2=[]\r\n",
        "    def get_colors(zed_colors,x,y):\r\n",
        "        tmp = zed_depthfloat_to_abgr(zed_colors[x, y])\r\n",
        "        tmp = [tmp[3], tmp[2], tmp[1]]  # ABGR to RGB\r\n",
        "        tmp = np.array(tmp).astype(np.float64) / 255.  # for ply (color is double)\r\n",
        "        return tmp\r\n",
        "    for i, goodMatch in enumerate(goodMatches):\r\n",
        "        p1=np.array(kp1[goodMatch.queryIdx].pt,dtype=np.int)\r\n",
        "        p2=np.array(kp2[goodMatch.trainIdx].pt,dtype=np.int)\r\n",
        "        pts1=imgdic.pcd0[p1[1],p1[0]]\r\n",
        "        pts2=imgdic.pcd1[p2[1],p2[0]]\r\n",
        "        if np.isnan(np.mean(pts1))  or np.isnan(np.mean(pts2)) or np.isinf(np.mean(pts1)) or np.isinf(np.mean(pts2)):\r\n",
        "            continue\r\n",
        "        cols1.append(get_colors(imgdic.pcd0[:, :, 3],p1[1],p1[0]))\r\n",
        "        cols2.append(get_colors(imgdic.pcd1[:, :, 3],p2[1],p2[0]))\r\n",
        "        pts_obj1.append(pts1[:3])\r\n",
        "        pts_obj2.append(pts2[:3])\r\n",
        "    ply1=make_pcd(np.array(pts_obj1),np.array(cols1))\r\n",
        "    ply2=make_pcd(np.array(pts_obj2),np.array(cols2))\r\n",
        "    return ply1,ply2\r\n",
        "\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfEVhr5WE5gD"
      },
      "source": [
        "##main 関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F998xBmIvESH"
      },
      "source": [
        "if FLAGS.model_type == 'pb':\r\n",
        "    reg_model_path = os.path.join(FLAGS.reg_model, 'reg.pb')\r\n",
        "    loc_model_path = os.path.join(FLAGS.loc_model, 'loc.pb')\r\n",
        "    aug_model_path = os.path.join(FLAGS.loc_model, 'aug.pb')\r\n",
        "elif FLAGS.model_type == 'ckpt':\r\n",
        "    reg_model_path = os.path.join(FLAGS.reg_model, 'model.ckpt-550000')\r\n",
        "    loc_model_path = os.path.join(FLAGS.loc_model, 'model.ckpt-400000')\r\n",
        "    aug_model_path = os.path.join(FLAGS.loc_model, 'model.ckpt-400000')\r\n",
        "else:\r\n",
        "    raise NotImplementedError\r\n",
        "\r\n",
        "img_paths = [FLAGS.img1_path, FLAGS.img2_path]\r\n",
        "# load testing images.\r\n",
        "rgb_list, gray_list = load_imgs(img_paths)\r\n",
        "# extract regional features.\r\n",
        "reg_feat_list = extract_regional_features(rgb_list, reg_model_path)\r\n",
        "# extract local features and keypoint matchability.\r\n",
        "cv_kpts_list, loc_info_list, loc_feat_list, sift_feat_list = extract_local_features(\r\n",
        "    gray_list, loc_model_path)\r\n",
        "# extract augmented features.\r\n",
        "aug_feat_list = extract_augmented_features(reg_feat_list, loc_info_list, aug_model_path)\r\n",
        "# feature matching and draw matches.\r\n",
        "matcher = MatcherWrapper()\r\n",
        "sift_match, sift_mask = matcher.get_matches(\r\n",
        "    sift_feat_list[0], sift_feat_list[1], cv_kpts_list[0], cv_kpts_list[1],\r\n",
        "    ratio=0.8 if FLAGS.ratio_test else None, cross_check=FLAGS.cross_check,\r\n",
        "    err_thld=3, ransac=True, info='SIFT feautre')\r\n",
        "\r\n",
        "base_match, base_mask = matcher.get_matches(\r\n",
        "    loc_feat_list[0], loc_feat_list[1], cv_kpts_list[0], cv_kpts_list[1],\r\n",
        "    ratio=0.89 if FLAGS.ratio_test else None, cross_check=FLAGS.cross_check,\r\n",
        "    err_thld=3, ransac=True, info='Raw local feature')\r\n",
        "\r\n",
        "aug_match, aug_mask = matcher.get_matches(\r\n",
        "    aug_feat_list[0], aug_feat_list[1], cv_kpts_list[0], cv_kpts_list[1],\r\n",
        "    ratio=0.89 if FLAGS.ratio_test else None, cross_check=FLAGS.cross_check,\r\n",
        "    err_thld=3, ransac=True, info='Augmented local feature')\r\n",
        "\r\n",
        "sift_disp = matcher.draw_matches(\r\n",
        "    rgb_list[0], cv_kpts_list[0], rgb_list[1], cv_kpts_list[1], sift_match, sift_mask)\r\n",
        "base_disp = matcher.draw_matches(\r\n",
        "    rgb_list[0], cv_kpts_list[0], rgb_list[1], cv_kpts_list[1], base_match, base_mask)\r\n",
        "aug_disp = matcher.draw_matches(\r\n",
        "    rgb_list[0], cv_kpts_list[0], rgb_list[1], cv_kpts_list[1], aug_match, aug_mask)\r\n",
        "\r\n",
        "rows, cols = sift_disp.shape[0:2]\r\n",
        "white = (np.ones((int(rows / 50), cols, 3)) * 255).astype(np.uint8)\r\n",
        "disp = np.concatenate([sift_disp, white, base_disp, white, aug_disp], axis=0)\r\n",
        "cv2.imwrite(\"rgb01.png\",disp)\r\n",
        "plt.xticks([])\r\n",
        "plt.yticks([])\r\n",
        "plt.imshow(disp)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHORcgulneUN",
        "outputId": "66cdecf0-e6f8-40b0-f89a-47205fec5e39"
      },
      "source": [
        "cv2.imwrite(\"{bp}rgb01.png\",disp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0I9lk0NYDCz"
      },
      "source": [
        "def point2dTo3d(point,cam):\r\n",
        "    z=point[2]/cam.depthScale\r\n",
        "    x=(point[0]-cam.cx)*z/cam.fx\r\n",
        "    y=(point[1]-cam.cy)*z/cam.fy\r\n",
        "    return [x,y,z]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_-tKqMduMb-"
      },
      "source": [
        "import numpy as np\r\n",
        "def make_pcd(points, colors):\r\n",
        "    pcd = open3d.geometry.PointCloud()\r\n",
        "    pcd.points = open3d.utility.Vector3dVector(points)\r\n",
        "    pcd.colors = open3d.utility.Vector3dVector(colors)\r\n",
        "    return pcd\r\n",
        "def make_merge(pcds):\r\n",
        "  points=[]\r\n",
        "  colors=[]\r\n",
        "  for pcd in pcds:\r\n",
        "     points.extend(np.array(pcd.points))\r\n",
        "     colors.extend(np.array(pcd.colors))\r\n",
        "  return make_pcd(points, colors)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSVMA4Z8uRcc",
        "outputId": "1aa4a383-a889-4092-f3b9-b20be792435f"
      },
      "source": [
        "import open3d\r\n",
        "import copy\r\n",
        "\r\n",
        "\r\n",
        "cams_para=[cam_zed2_21888201_left_hd1080,cam_zed2_22378008_left_hd1080,cam_zed2_22115402_left_hd1080]\r\n",
        "trans_sift,pts_obj1_sift,pts_obj2_sift=get_good_matches_pts(sift_match,cv_kpts_list[0],cv_kpts_list[1],imgdic,cams_para)\r\n",
        "trans_base,pts_obj1_base,pts_obj2_base=get_good_matches_pts(base_match,cv_kpts_list[0],cv_kpts_list[1],imgdic,cams_para)\r\n",
        "trans_aug,pts_obj1_aug,pts_obj2_aug=get_good_matches_pts(aug_match,cv_kpts_list[0],cv_kpts_list[1],imgdic,cams_para)\r\n",
        "\r\n",
        "\r\n",
        "cloud0=open3d.io.read_point_cloud(f'{bp}/pcd_mask_cam0.ply')\r\n",
        "cloud1=open3d.io.read_point_cloud(f'{bp}/pcd_mask_cam1.ply')\r\n",
        "\r\n",
        "ext='sift'\r\n",
        "cloud0_t=copy.deepcopy(cloud0)\r\n",
        "cloud0_gm=cloud0_t.transform(trans_sift)\r\n",
        "open3d.io.write_point_cloud(f'{bp}{ext}_pcd_trans_0_solvePnP.ply', cloud0_gm)\r\n",
        "ply_merge=make_merge([cloud0_gm,cloud1])\r\n",
        "open3d.io.write_point_cloud(f'{bp}{ext}_pcd_merge_solvePnP.ply', ply_merge)\r\n",
        "\r\n",
        "\r\n",
        "ext='base'\r\n",
        "cloud0_t=copy.deepcopy(cloud0)\r\n",
        "cloud0_gm=cloud0_t.transform(trans_base)\r\n",
        "open3d.io.write_point_cloud(f'{bp}{ext}_pcd_trans_0_solvePnP.ply', cloud0_gm)\r\n",
        "ply_merge=make_merge([cloud0_gm,cloud1])\r\n",
        "open3d.io.write_point_cloud(f'{bp}{ext}_pcd_merge_solvePnP.ply', ply_merge)\r\n",
        "\r\n",
        "\r\n",
        "ext='aug'\r\n",
        "cloud0_t=copy.deepcopy(cloud0)\r\n",
        "cloud0_gm=cloud0_t.transform(trans_aug)\r\n",
        "open3d.io.write_point_cloud(f'{bp}{ext}_pcd_trans_0_solvePnP.ply', cloud0_gm)\r\n",
        "ply_merge=make_merge([cloud0_gm,cloud1])\r\n",
        "open3d.io.write_point_cloud(f'{bp}{ext}_pcd_merge_solvePnP.ply', ply_merge)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:160: RuntimeWarning: invalid value encountered in reduce\n",
            "  ret = umr_sum(arr, axis, dtype, out, keepdims)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "pts_obj1:3990,pts_obj2:3990\n",
            "pts_obj1:3994,pts_obj2:3994\n",
            "pts_obj1:4011,pts_obj2:4011\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pNuYEsMXn9i"
      },
      "source": [
        "# cams_para=[cam_zed2_21888201_left_hd1080,cam_zed2_22378008_left_hd1080,cam_zed2_22115402_left_hd1080]\r\n",
        "# # cams_para=[cam_zed2_21888201_left_hd1080,cam_zed2_21888201_left_hd1080,cam_zed2_22115402_left_hd1080]\r\n",
        "# trans12,pts_obj1,pts_obj2=get_good_matches_pts(base_match,cv_kpts_list[0],cv_kpts_list[1],imgdic,cams_para)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhosPAKtYQNf",
        "outputId": "9c8d6292-89c3-45b3-8d99-13c45453cefe"
      },
      "source": [
        "# import open3d\r\n",
        "# import copy\r\n",
        "# cloud0=open3d.io.read_point_cloud(f'{bp}/pcd_mask_cam0.ply')\r\n",
        "# cloud1=open3d.io.read_point_cloud(f'{bp}/pcd_mask_cam1.ply')\r\n",
        "# # cloud0_t=copy.deepcopy(cloud1)\r\n",
        "# cloud0_gm=cloud0.transform(trans12)\r\n",
        "# ext='sift'\r\n",
        "# open3d.io.write_point_cloud(f'{bp}{ext}_pcd_trans_0_solvePnP.ply', cloud0_gm)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbllqBmPEW6H"
      },
      "source": [
        "# https://github.com/lzx551402/contextdesc\r\n",
        "# https://github.com/neka-nat/probreg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5c4Dk6D9fCh"
      },
      "source": [
        "#probreg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBxPpFaK9iq8"
      },
      "source": [
        "##install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQr1uEMW9ksm"
      },
      "source": [
        "# https://github.com/neka-nat/probreg\r\n",
        "!pip install cupy\r\n",
        "!pip install probreg\r\n",
        "# !pip install open3d==0.10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5sN92wi3e8h",
        "outputId": "dd55ed37-abd1-4004-c575-ec954b42ce90"
      },
      "source": [
        "%cd /content/drive/MyDrive/00_work/004_pose_estimation\r\n",
        "# !git clone https://github.com/neka-nat/probreg.git --recursive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/00_work/004_pose_estimation'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u71A9tK3163",
        "outputId": "eac54e15-0ca8-4f7a-addf-6f8269d5429f"
      },
      "source": [
        "! echo $PYTHONPATH\r\n",
        "import os\r\n",
        "os.environ['PYTHONPATH'] = \"/env/python:/content/drive/MyDrive/00_work/004_pose_estimation/probreg/examples\"\r\n",
        "! echo $PYTHONPATH\r\n",
        "import numpy as np\r\n",
        "import open3d\r\n",
        "def make_pcd(points, colors):\r\n",
        "    pcd = open3d.geometry.PointCloud()\r\n",
        "    pcd.points = open3d.utility.Vector3dVector(points)\r\n",
        "    pcd.colors = open3d.utility.Vector3dVector(colors)\r\n",
        "    return pcd\r\n",
        "def make_merge(pcds):\r\n",
        "  points=[]\r\n",
        "  colors=[]\r\n",
        "  for pcd in pcds:\r\n",
        "     points.extend(np.array(pcd.points))\r\n",
        "     colors.extend(np.array(pcd.colors))\r\n",
        "  return make_pcd(points, colors)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/env/python:{bp}/contextdesc/\n",
            "/env/python:/content/drive/MyDrive/00_work/004_pose_estimation/probreg/examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfodWoLd-BgA"
      },
      "source": [
        "##sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQ3VVS8t-Dk0",
        "outputId": "244711f6-5228-4c17-86f1-7bc706afcea0"
      },
      "source": [
        "import copy\r\n",
        "import numpy as np\r\n",
        "import open3d as o3\r\n",
        "from probreg import cpd\r\n",
        "\r\n",
        "# load source and target point cloud\r\n",
        "bo='/content/drive/MyDrive/00_work/004_pose_estimation/probreg/result/'\r\n",
        "# bp='/content/drive/MyDrive/00_work/004_pose_estimation/probreg/examples/'\r\n",
        "bp='/content/drive/MyDrive/00_work/004_pose_estimation/contextdesc/imgs/'\r\n",
        "# source = o3.io.read_point_cloud(f'{bp}bunny.pcd')\r\n",
        "# target = copy.deepcopy(source)\r\n",
        "# # transform target point \r\n",
        "# th = np.deg2rad(30.0)\r\n",
        "# target.transform(np.array([[np.cos(th), -np.sin(th), 0.0, 0.0],\r\n",
        "#                            [np.sin(th), np.cos(th), 0.0, 0.0],\r\n",
        "#                            [0.0, 0.0, 1.0, 0.0],\r\n",
        "#                            [0.0, 0.0, 0.0, 1.0]]))\r\n",
        "\r\n",
        "source_r = o3.io.read_point_cloud(f'{bp}pcd_mask_cam0.ply')\r\n",
        "target_r = o3.io.read_point_cloud(f'{bp}pcd_mask_cam1.ply')\r\n",
        "# source = source_r.voxel_down_sample(voxel_size=0.005)\r\n",
        "# target = target_r.voxel_down_sample(voxel_size=0.005)\r\n",
        "\r\n",
        "source = source_r.voxel_down_sample(voxel_size=20)\r\n",
        "target = target_r.voxel_down_sample(voxel_size=20)\r\n",
        "\r\n",
        "# compute cpd registration\r\n",
        "tf_param, _, _ = cpd.registration_cpd(source, target)\r\n",
        "result = copy.deepcopy(source)\r\n",
        "result.points = tf_param.transform(result.points)\r\n",
        "\r\n",
        "# draw result\r\n",
        "# source.paint_uniform_color([1, 0, 0])\r\n",
        "# target.paint_uniform_color([0, 1, 0])\r\n",
        "# result.paint_uniform_color([0, 0, 1])\r\n",
        "ply_merge=make_merge([ target, result])\r\n",
        "\r\n",
        "open3d.io.write_point_cloud(f'{bo}pcd_merge_probreg_cam01_cpd.ply', ply_merge)\r\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhF1ZBfTI7fR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXcm_9SeFVwX"
      },
      "source": [
        "##probreg/examples/cpd_affine3d_cuda.py "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojHhnkBIG_5k"
      },
      "source": [
        "##cpd_nonrigid3d_cuda.py cpd_affine3d_cuda.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmzhGKoH7Xwp"
      },
      "source": [
        "##function define"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2cYhO4c-uVt",
        "outputId": "3f2f86a8-da62-4651-9409-f267e489fced"
      },
      "source": [
        "%cd /content/drive/MyDrive/00_work/004_pose_estimation/probreg/examples\r\n",
        "import numpy as np\r\n",
        "import copy\r\n",
        "use_cuda = True\r\n",
        "if use_cuda:\r\n",
        "    import cupy as cp\r\n",
        "    to_cpu = cp.asnumpy\r\n",
        "    cp.cuda.set_allocator(cp.cuda.MemoryPool().malloc)\r\n",
        "else:\r\n",
        "    cp = np\r\n",
        "    to_cpu = lambda x: x\r\n",
        "import open3d as o3\r\n",
        "import transformations as trans\r\n",
        "from probreg import cpd\r\n",
        "from probreg import callbacks\r\n",
        "import utils\r\n",
        "import time\r\n",
        "\r\n",
        "#https://github.com/neka-nat/probreg/blob/master/examples/cpd_rigid_cuda.py\r\n",
        "def reg_rigid_cpd(source,target):\r\n",
        "  source_pt = cp.asarray(source.points, dtype=cp.float32)\r\n",
        "  target_pt = cp.asarray(target.points, dtype=cp.float32)\r\n",
        "\r\n",
        "  acpd = cpd.RigidCPD(source_pt, use_cuda=use_cuda)\r\n",
        "  start = time.time()\r\n",
        "  tf_param, _, _ = acpd.registration(target_pt)\r\n",
        "  elapsed = time.time() - start\r\n",
        "  print(\"time: \", elapsed)\r\n",
        "  # print(\"result: \", to_cpu(tf_param.b), to_cpu(tf_param.t))\r\n",
        "\r\n",
        "  points=tf_param.transform(source_pt)\r\n",
        "  points_np = cp. asnumpy(points) \r\n",
        "  result=make_pcd(points_np,source.colors)\r\n",
        "  return result,target\r\n",
        "def reg_non_rigid_cpd(source,target):\r\n",
        "  source_pt = cp.asarray(source.points, dtype=cp.float32)\r\n",
        "  target_pt = cp.asarray(target.points, dtype=cp.float32)\r\n",
        "\r\n",
        "  acpd = cpd.NonRigidCPD(source_pt, use_cuda=use_cuda)\r\n",
        "  start = time.time()\r\n",
        "  tf_param, _, _ = acpd.registration(target_pt)\r\n",
        "  elapsed = time.time() - start\r\n",
        "  print(\"time: \", elapsed)\r\n",
        "  # print(\"result: \", to_cpu(tf_param.b), to_cpu(tf_param.t))\r\n",
        "\r\n",
        "  points=tf_param.transform(source_pt)\r\n",
        "  points_np = cp. asnumpy(points) \r\n",
        "  result=make_pcd(points_np,source.colors)\r\n",
        "  return result,target\r\n",
        "def reg_affine_cpd(source,target):\r\n",
        "  source_pt = cp.asarray(source.points, dtype=cp.float32)\r\n",
        "  target_pt = cp.asarray(target.points, dtype=cp.float32)\r\n",
        "\r\n",
        "  acpd = cpd.AffineCPD(source_pt, use_cuda=use_cuda)\r\n",
        "  start = time.time()\r\n",
        "  tf_param, _, _ = acpd.registration(target_pt)\r\n",
        "  elapsed = time.time() - start\r\n",
        "  print(\"time: \", elapsed)\r\n",
        "  # print(\"result: \", to_cpu(tf_param.b), to_cpu(tf_param.t))\r\n",
        "\r\n",
        "  points=tf_param.transform(source_pt)\r\n",
        "  points_np = cp. asnumpy(points) \r\n",
        "  result=make_pcd(points_np,source.colors)\r\n",
        "  return result,target\r\n",
        "def reg_cpd(source_pt,target_pt,fun_cpd):\r\n",
        "  acpd = fun_cpd(source_pt, use_cuda=use_cuda)\r\n",
        "  tf_param, _, _ = acpd.registration(target_pt)\r\n",
        "  return tf_param\r\n",
        "def tran_tf_param(tf_param,source_r):\r\n",
        "  points_src=tf_param.transform(cp.asarray(source_r.points, dtype=cp.float32))\r\n",
        "  points_src=to_cpu(points_src)\r\n",
        "  result_trans=make_pcd(points_src,source_r.colors)\r\n",
        "  return result_trans"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/00_work/004_pose_estimation/probreg/examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDLAOYhAUP9X"
      },
      "source": [
        "# print(\"result: \", to_cpu(tf_param.b), to_cpu(tf_param.t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRt-a37Q7VEA"
      },
      "source": [
        "##RigidCPD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vcCMEcyT2D1",
        "outputId": "95ec0a28-e420-40ba-ba20-ea8f956cf17d"
      },
      "source": [
        "source_r = o3.io.read_point_cloud(f'{bp}pcd_mask_cam0.ply')\r\n",
        "target_r = o3.io.read_point_cloud(f'{bp}pcd_mask_cam1.ply')\r\n",
        "\r\n",
        "source = source_r.voxel_down_sample(voxel_size=20)\r\n",
        "target = target_r.voxel_down_sample(voxel_size=20)\r\n",
        "result,target_reg=reg_rigid_cpd(source,target)\r\n",
        "ply_merge=make_merge([ target_reg, result])\r\n",
        "open3d.io.write_point_cloud(f'{bo}pcd_merge_cam01_probreg.RigidCPD.t.ply', target)\r\n",
        "open3d.io.write_point_cloud(f'{bo}pcd_merge_cam01_probreg.RigidCPD.s.ply', result)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time:  20.867454290390015\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91ekAJg57dyJ"
      },
      "source": [
        "##AffineCPD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fDjb0MHjH7V"
      },
      "source": [
        "source_r = o3.io.read_point_cloud(f'{bp}pcd_mask_cam0.ply')\r\n",
        "target_r = o3.io.read_point_cloud(f'{bp}pcd_mask_cam1.ply')\r\n",
        "\r\n",
        "source = source_r.voxel_down_sample(voxel_size=20)\r\n",
        "target = target_r.voxel_down_sample(voxel_size=20)\r\n",
        "result,target_reg=reg_affine_cpd(source,target)\r\n",
        "ply_merge=make_merge([ target_reg, result])\r\n",
        "open3d.io.write_point_cloud(f'{bo}pcd_merge_cam01_probreg.AffineCPD.t.ply', target)\r\n",
        "open3d.io.write_point_cloud(f'{bo}pcd_merge_cam01_probreg.AffineCPD.s.ply', result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8kkYPiM7fvn"
      },
      "source": [
        "##NonRigidCPD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUO8lNHkjIUo"
      },
      "source": [
        "source_r = o3.io.read_point_cloud(f'{bp}pcd_mask_cam0.ply')\r\n",
        "target_r = o3.io.read_point_cloud(f'{bp}pcd_mask_cam1.ply')\r\n",
        "\r\n",
        "source = source_r.voxel_down_sample(voxel_size=20)\r\n",
        "target = target_r.voxel_down_sample(voxel_size=20)\r\n",
        "result,target_reg=reg_rigid_cpd(source,target)\r\n",
        "ply_merge=make_merge([ target_reg, result])\r\n",
        "open3d.io.write_point_cloud(f'{bo}pcd_merge_cam01_probreg.NonRigidCPD.t.ply', target)\r\n",
        "open3d.io.write_point_cloud(f'{bo}pcd_merge_cam01_probreg.NonRigidCPD.s.ply', result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unF4fb8w8EPS"
      },
      "source": [
        "## common call transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nlcUGJRbFLM",
        "outputId": "c863bd7e-0847-470e-faac-7e1bbc967dd4"
      },
      "source": [
        "bo='/content/drive/MyDrive/00_work/004_pose_estimation/probreg/result/'\r\n",
        "bp='/content/drive/MyDrive/00_work/004_pose_estimation/contextdesc/imgs/'\r\n",
        "source_r = o3.io.read_point_cloud(f'{bp}pcd_mask_cam0.ply')\r\n",
        "target_r = o3.io.read_point_cloud(f'{bp}pcd_mask_cam1.ply')\r\n",
        "source = source_r.voxel_down_sample(voxel_size=20)\r\n",
        "target = target_r.voxel_down_sample(voxel_size=20)\r\n",
        "source_pt = cp.asarray(source.points, dtype=cp.float32)\r\n",
        "target_pt = cp.asarray(target.points, dtype=cp.float32)\r\n",
        "# tf_param_non_rig=reg_cpd(source_pt,target_pt,cpd.NonRigidCPD)\r\n",
        "tf_param_non_rig=reg_cpd(source_pt,target_pt,cpd.AffineCPD)\r\n",
        "# tf_param_rig=reg_cpd(source_pt,target_pt,cpd.RigidCPD) cpd.AffineCPD\r\n",
        "ply=tran_tf_param(tf_param_non_rig,source_r)\r\n",
        "open3d.io.write_point_cloud(f'{bo}pcd_merge_cam01_probreg_AffineCPD_s2.ply', ply)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GYdEW-dqLgt"
      },
      "source": [
        "def generateTransMatrixRt(t, R):\r\n",
        "    transMatrix = np.eye(4, 4)\r\n",
        "    for y in range(0, 3):\r\n",
        "        for x in range(0, 3):\r\n",
        "            transMatrix[y, x] = R[y, x]\r\n",
        "        transMatrix[y, 3] = t[y]\r\n",
        "    return transMatrix"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge8HSWQAuvT5"
      },
      "source": [
        "## test pts_obj1_aug"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiLy-5yOuxRr",
        "outputId": "52854280-ed5b-4b51-e468-ff2453908cb2"
      },
      "source": [
        "import open3d as o3\r\n",
        "import cupy as cp\r\n",
        "bo='/content/drive/MyDrive/00_work/004_pose_estimation/probreg/result/'\r\n",
        "bp='/content/drive/MyDrive/00_work/004_pose_estimation/contextdesc/imgs/'\r\n",
        "pts_obj1_aug_t,pts_obj2_aug_t=get_key_points(aug_match,cv_kpts_list[0],cv_kpts_list[1],imgdic)\r\n",
        "source_r = o3.io.read_point_cloud(f'{bp}pcd_mask_cam0.ply')\r\n",
        "target_r = o3.io.read_point_cloud(f'{bp}pcd_mask_cam1.ply')\r\n",
        "source_pt = cp.asarray(pts_obj1_aug_t, dtype=cp.float32)\r\n",
        "target_pt = cp.asarray(pts_obj2_aug_t, dtype=cp.float32)\r\n",
        "tf_param_rig=reg_cpd(source_pt,target_pt,cpd.RigidCPD)\r\n",
        "ply=tran_tf_param(tf_param_rig,source_r)\r\n",
        "open3d.io.write_point_cloud(f'{bo}pcd_merge_cam01_probreg.aug_match.RigidCPD.s.ply', ply)\r\n",
        "open3d.io.write_point_cloud(f'{bo}pcd_merge_cam01_probreg.aug_match.RigidCPD.t.ply', target_r)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:160: RuntimeWarning: invalid value encountered in reduce\n",
            "  ret = umr_sum(arr, axis, dtype, out, keepdims)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm0o8uNN-gF1"
      },
      "source": [
        "##ransac_icp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msrpcixK-ijE"
      },
      "source": [
        "#https://qiita.com/tttamaki/items/648422860869bbccc72d\r\n",
        "import numpy as np\r\n",
        "import open3d as py3d\r\n",
        "import cv2\r\n",
        "import os\r\n",
        "# pip install open3d==0.10.0.1\r\n",
        "# import pcl\r\n",
        "class ransac_icp:\r\n",
        "    def __init__(self):\r\n",
        "        self.RANSAC = py3d.registration.registration_ransac_based_on_feature_matching\r\n",
        "        self.ICP = py3d.registration.registration_icp\r\n",
        "        self.FPFH = py3d.registration.compute_fpfh_feature\r\n",
        "        self.GET_GTG = py3d.registration.get_information_matrix_from_point_clouds\r\n",
        "\r\n",
        "    def register(self,pcd1, pcd2, size):\r\n",
        "        # ペアの点群を位置合わせ\r\n",
        "\r\n",
        "        kdt_n = py3d.geometry.KDTreeSearchParamHybrid(radius=size, max_nn=50)\r\n",
        "        kdt_f = py3d.geometry.KDTreeSearchParamHybrid(radius=size *2, max_nn=50)\r\n",
        "\r\n",
        "        # ダウンサンプリング\r\n",
        "        pcd1_d = pcd1.voxel_down_sample( size)\r\n",
        "        pcd2_d = pcd2.voxel_down_sample( size)\r\n",
        "        pcd1_d.estimate_normals( kdt_n)\r\n",
        "        pcd2_d.estimate_normals( kdt_n)\r\n",
        "        print(\"voxel_down_sample:\",np.array(pcd1_d.points).shape[0]/np.array(pcd1.points).shape[0])\r\n",
        "        # 特徴量計算\r\n",
        "        pcd1_f = self.FPFH(pcd1_d, kdt_f)\r\n",
        "        pcd2_f = self.FPFH(pcd2_d, kdt_f)\r\n",
        "\r\n",
        "        # 準備\r\n",
        "        checker = [py3d.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\r\n",
        "                   py3d.registration.CorrespondenceCheckerBasedOnDistance(size * 2)]\r\n",
        "\r\n",
        "        est_ptp = py3d.registration.TransformationEstimationPointToPoint()\r\n",
        "        est_ptpln = py3d.registration.TransformationEstimationPointToPlane()\r\n",
        "\r\n",
        "        criteria = py3d.registration.RANSACConvergenceCriteria(max_iteration=400000,\r\n",
        "                                                  max_validation=500)\r\n",
        "        # RANSACマッチング\r\n",
        "        result1 = self.RANSAC(pcd1_d, pcd2_d,\r\n",
        "                         pcd1_f, pcd2_f,\r\n",
        "                         max_correspondence_distance=size * 2,\r\n",
        "                         estimation_method=est_ptp,\r\n",
        "                         ransac_n=4,\r\n",
        "                         checkers=checker,\r\n",
        "                         criteria=criteria)\r\n",
        "        # ICPで微修正\r\n",
        "        result2 = self.ICP(pcd1, pcd2, size, result1.transformation, est_ptpln)\r\n",
        "\r\n",
        "        return result2.transformation\r\n",
        "\r\n",
        "\r\n",
        "    def merge(self,pcds):\r\n",
        "        # 複数の点群を1つの点群にマージする\r\n",
        "\r\n",
        "        all_points = []\r\n",
        "        all_colors = []\r\n",
        "        for pcd in pcds:\r\n",
        "            all_points.append(np.asarray(pcd.points))\r\n",
        "            all_colors.append(np.asarray(pcd.colors))\r\n",
        "\r\n",
        "        merged_pcd = py3d.geometry.PointCloud()\r\n",
        "        merged_pcd.points = py3d.utility.Vector3dVector(np.vstack(all_points))\r\n",
        "        merged_pcd.colors = py3d.utility.Vector3dVector(np.vstack(all_points))\r\n",
        "\r\n",
        "        return merged_pcd\r\n",
        "\r\n",
        "\r\n",
        "    def add_color_normal(self,pcd,size): # in-place coloring and adding normal\r\n",
        "        # pcd.paint_uniform_color(np.random.rand(3))\r\n",
        "        kdt_n = py3d.geometry.KDTreeSearchParamHybrid(radius=size, max_nn=50)\r\n",
        "        pcd.estimate_normals( kdt_n)\r\n",
        "        # py3d.estimate_normals(pcd,kdt_n)\r\n",
        "        return pcd\r\n",
        "\r\n",
        "    def load_pcds(self,pcd_files):\r\n",
        "\r\n",
        "        pcds = []\r\n",
        "        for f in pcd_files:\r\n",
        "            pcd = py3d.io.read_point_cloud(f)\r\n",
        "            pcd_tem=self.remove_noise_ply(pcd)\r\n",
        "            cnt_org=np.array(pcd.points).shape[0]\r\n",
        "            cnt_noise=np.array(pcd_tem.points).shape[0]\r\n",
        "            if cnt_noise/cnt_org>0.5:\r\n",
        "                pcd=pcd_tem\r\n",
        "            pcds.append(pcd)\r\n",
        "        return pcds\r\n",
        "\r\n",
        "\r\n",
        "    def align_pcds(self,pcds, size):\r\n",
        "        # 複数の点群を位置合わせ\r\n",
        "\r\n",
        "        pose_graph = py3d.registration.PoseGraph()\r\n",
        "        accum_pose = np.identity(4) # id0から各ノードへの累積姿勢\r\n",
        "        pose_graph.nodes.append(py3d.registration.PoseGraphNode(accum_pose))\r\n",
        "\r\n",
        "        n_pcds = len(pcds)\r\n",
        "        for source_id in range(n_pcds):\r\n",
        "            for target_id in range(source_id + 1, n_pcds):\r\n",
        "                source = pcds[source_id]\r\n",
        "                target = pcds[target_id]\r\n",
        "\r\n",
        "                trans = self.register(source, target, size)\r\n",
        "                GTG_mat = self.GET_GTG(source, target, size, trans) # これが点の情報を含む\r\n",
        "\r\n",
        "                if target_id == source_id + 1: # 次のidの点群ならaccum_poseにposeを積算\r\n",
        "                    accum_pose = trans @ accum_pose\r\n",
        "                    pose_graph.nodes.append(py3d.registration.PoseGraphNode(np.linalg.inv(accum_pose))) # 各ノードは，このノードのidからid0への変換姿勢を持つので，invする\r\n",
        "                    # そうでないならnodeは作らない\r\n",
        "                pose_graph.edges.append(py3d.registration.PoseGraphEdge(source_id,\r\n",
        "                                                           target_id,\r\n",
        "                                                           trans,\r\n",
        "                                                           GTG_mat,\r\n",
        "                                                           uncertain=True)) # bunnyの場合，隣でも怪しいので全部True\r\n",
        "\r\n",
        "\r\n",
        "        # 設定\r\n",
        "        solver = py3d.registration.GlobalOptimizationLevenbergMarquardt()\r\n",
        "        criteria = py3d.registration.GlobalOptimizationConvergenceCriteria()\r\n",
        "        option = py3d.registration.GlobalOptimizationOption(\r\n",
        "                 max_correspondence_distance=size / 10,\r\n",
        "                 edge_prune_threshold=size / 10,\r\n",
        "                 reference_node=0)\r\n",
        "\r\n",
        "        # 最適化\r\n",
        "        py3d.registration.global_optimization(pose_graph,\r\n",
        "                                method=solver,\r\n",
        "                                criteria=criteria,\r\n",
        "                                option=option)\r\n",
        "\r\n",
        "        # 推定した姿勢で点群を変換\r\n",
        "        translst=[]\r\n",
        "        for pcd_id in range(n_pcds):\r\n",
        "            trans = pose_graph.nodes[pcd_id].pose\r\n",
        "            print(\"transform matrix:\",trans)\r\n",
        "            pcds[pcd_id].transform(trans)\r\n",
        "            translst.append(trans)\r\n",
        "\r\n",
        "\r\n",
        "        return pcds,translst\r\n",
        "\r\n",
        "    def make_pcd(self,points, colors):\r\n",
        "      pcd = py3d.geometry.PointCloud()\r\n",
        "      pcd.points = py3d.utility.Vector3dVector(points)\r\n",
        "      pcd.colors = py3d.utility.Vector3dVector(colors)\r\n",
        "      return pcd\r\n",
        "    def merge(self,pcds):\r\n",
        "        # 複数の点群を1つの点群にマージする\r\n",
        "\r\n",
        "        all_points = []\r\n",
        "        for pcd in pcds:\r\n",
        "            all_points.append(np.asarray(pcd.points))\r\n",
        "\r\n",
        "        merged_pcd = py3d.PointCloud()\r\n",
        "        merged_pcd.points = py3d.Vector3dVector(np.vstack(all_points))\r\n",
        "\r\n",
        "        return merged_pcd\r\n",
        "    #https://github.com/aipiano/guided-filter-point-cloud-denoise/blob/master/main.py\r\n",
        "    #https://github.com/sakizuki/SSII2018_Tutorial_Open3D/blob/master/Python/kdtree.py\r\n",
        "    def guided_filter(self,pcd, radius=0.01, epsilon=0.1):\r\n",
        "        kdtree = py3d.geometry.KDTreeFlann(pcd)\r\n",
        "        points_copy = np.array(pcd.points)\r\n",
        "        points = np.asarray(pcd.points)\r\n",
        "        num_points = len(pcd.points)\r\n",
        "\r\n",
        "        for i in range(num_points):\r\n",
        "            # 1.RNNの方法\r\n",
        "            k, idx, _ = kdtree.search_radius_vector_3d(pcd.points[i], radius)\r\n",
        "            # 2.KNNの方法\r\n",
        "            # k, idx, _ = kdtree.search_knn_vector_3d(pcd.points[i], 200)\r\n",
        "            # 3.RKNNの方法\r\n",
        "            # k, idx, _ = kdtree.search_hybrid_vector_3d(pcd.points[i], radius=0.1, max_nn=100)\r\n",
        "            if k < 3:\r\n",
        "                continue\r\n",
        "\r\n",
        "            neighbors = points[idx, :]\r\n",
        "            mean = np.mean(neighbors, 0)\r\n",
        "            cov = np.cov(neighbors.T)\r\n",
        "            e = np.linalg.inv(cov + epsilon * np.eye(3))\r\n",
        "\r\n",
        "            A = cov @ e\r\n",
        "            b = mean - A @ mean\r\n",
        "\r\n",
        "            points_copy[i] = A @ points[i] + b\r\n",
        "\r\n",
        "        pcd.points = py3d.utility.Vector3dVector(points_copy)\r\n",
        "        # guided_filter(pcd, 0.01, 0.1)\r\n",
        "        return pcd\r\n",
        "\r\n",
        "    def remove_noise_ply(self,pcd):\r\n",
        "        # (1) Load a ply point cloud, print it, and render it\r\n",
        "        print(\"Load a ply point cloud, print it, and render it\")\r\n",
        "        # pcd = py3d.io.read_point_cloud(fn_pcd)\r\n",
        "        # py3d.visualization.draw_geometries([pcd])\r\n",
        "        # (2) Downsample the point cloud with a voxel\r\n",
        "        print(\"Downsample the point cloud with a voxel of 0.02\")\r\n",
        "        voxel_down_pcd = pcd.voxel_down_sample(voxel_size=0.02)\r\n",
        "        # py3d.visualization.draw_geometries([voxel_down_pcd])\r\n",
        "        # (3) Every 5th points are selected\r\n",
        "        print(\"Every 5th points are selected\")\r\n",
        "        uni_down_pcd = pcd.uniform_down_sample(every_k_points=5)\r\n",
        "        # py3d.visualization.draw_geometries([uni_down_pcd])\r\n",
        "        # (4) Statistical oulier removal\r\n",
        "        print(\"Statistical oulier removal\")\r\n",
        "        cl, ind = voxel_down_pcd.remove_statistical_outlier(nb_neighbors=20,\r\n",
        "                                                            std_ratio=2.0)\r\n",
        "        # display_inlier_outlier(voxel_down_pcd, ind)\r\n",
        "        # (5) Radius oulier removal\r\n",
        "        print(\"Radius oulier removal\")\r\n",
        "        # cl, ind = voxel_down_pcd.remove_radius_outlier(nb_points=16, radius=0.05)\r\n",
        "        cl, ind = voxel_down_pcd.remove_radius_outlier(nb_points=16, radius=2.5)\r\n",
        "        inlier_cloud = voxel_down_pcd.select_by_index(ind)\r\n",
        "        outlier_cloud = voxel_down_pcd.select_by_index(ind, invert=True)\r\n",
        "        # inlier_cloud, outlier_cloud = display_inlier_outlier(voxel_down_pcd, ind)\r\n",
        "        return inlier_cloud\r\n",
        "import struct\r\n",
        "def zed_depthfloat_to_abgr(f):\r\n",
        "    \"\"\"\r\n",
        "    ZED pcd data format:\r\n",
        "      ----------------------------------------------------------\r\n",
        "      https://www.stereolabs.com/docs/depth-sensing/using-depth/\r\n",
        "      ----------------------------------------------------------\r\n",
        "      The point cloud stores its data on 4 channels using 32-bit \r\n",
        "      float for each channel. \r\n",
        "      The last float is used to store color information, where \r\n",
        "      R, G, B, and alpha channels (4 x 8-bit) are concatenated \r\n",
        "      into a single 32-bit float. \r\n",
        "  \"\"\"\r\n",
        "    # https://stackoverflow.com/questions/23624212/how-to-convert-a-float-into-hex/38879403\r\n",
        "    if f == 0.:\r\n",
        "        return [0, 0, 0, 0]\r\n",
        "    else:\r\n",
        "        h = hex(struct.unpack('<I', struct.pack('<f', f))[0])\r\n",
        "        return [eval('0x' + a + b) for a, b in zip(h[::2], h[1::2]) if a + b != '0x']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZauhFe_pZMlr"
      },
      "source": [
        "##ransac_icp特徴ポイントの実施"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGXOih0yBLiJ",
        "outputId": "9c5442a3-7e9d-4dd3-b113-479e7b43eb79"
      },
      "source": [
        "pcd0,pcd1=get_key_ply(aug_match,cv_kpts_list[0],cv_kpts_list[1],imgdic)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:160: RuntimeWarning: invalid value encountered in reduce\n",
            "  ret = umr_sum(arr, axis, dtype, out, keepdims)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niIDxz0m-ryE",
        "outputId": "010baba4-b274-43b3-ae05-b414252387f1"
      },
      "source": [
        "ri=ransac_icp()\r\n",
        "pcds=[pcd0,pcd1]\r\n",
        "size=10\r\n",
        "for pcd in pcds:\r\n",
        "    si = np.abs((pcd.get_max_bound() - pcd.get_min_bound())).max() / 40\r\n",
        "    if  size < si:\r\n",
        "        size=si\r\n",
        "print(\"size:\",size)\r\n",
        "pcdsn=[]\r\n",
        "for pcd in pcds:\r\n",
        "    pcdn=ri.add_color_normal(pcd,size)\r\n",
        "    pcdsn.append(pcdn)\r\n",
        "\r\n",
        "pcd_aligned,translst = ri.align_pcds(pcdsn, size)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size: 469.05395660400393\n",
            "voxel_down_sample: 0.23235887096774194\n",
            "\u001b[1;33m[Open3D WARNING] Certain-edge subset of PoseGraph is not connected.\u001b[0;m\n",
            "transform matrix: [[1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]]\n",
            "transform matrix: [[ 9.70911699e-01  7.04301323e-02 -2.28845076e-01  5.56762669e+02]\n",
            " [-8.12062099e-02  9.95972420e-01 -3.80064543e-02  7.24299902e+01]\n",
            " [ 2.25246585e-01  5.54845524e-02  9.72720638e-01  8.64661677e+02]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcIJtuzOE7um",
        "outputId": "a8052db0-95e6-4727-c381-e9e45df12acb"
      },
      "source": [
        "open3d.io.write_point_cloud(f'{bo}pcd_merge_cam01.features.ransac_icp_0.ply', pcd_aligned[0])\r\n",
        "open3d.io.write_point_cloud(f'{bo}pcd_merge_cam01.features.ransac_icp_1.ply', pcd_aligned[1])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs7tRyPBGRIq",
        "outputId": "d1d4f2a8-fb89-45e3-94f2-dec120f0f0f7"
      },
      "source": [
        "pcd_aligned"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[geometry::PointCloud with 1984 points.,\n",
              " geometry::PointCloud with 1984 points.]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYCIS4TXCmuu"
      },
      "source": [
        "source_r = o3.io.read_point_cloud(f'{bp}pcd_mask_cam0.ply')\r\n",
        "target_r = o3.io.read_point_cloud(f'{bp}pcd_mask_cam1.ply')\r\n",
        "target_trans=target_r.transform(translst[1])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1HaMISUqPS1",
        "outputId": "67aac342-1c96-4fdc-b05d-1a581197996f"
      },
      "source": [
        "\r\n",
        "bo='/content/drive/MyDrive/00_work/004_pose_estimation/probreg/result/'\r\n",
        "open3d.io.write_point_cloud(f'{bo}pcd_merge_cam01_probreg.ransac_icp.t.ply', target_trans)\r\n",
        "open3d.io.write_point_cloud(f'{bo}pcd_merge_cam01_probreg.ransac_icp.s.ply', source_r)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g8g27dUGJPT"
      },
      "source": [
        "## time_measurement.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhFZyDatGNAD"
      },
      "source": [
        "# %cd /content/drive/MyDrive/00_work/004_pose_estimation/probreg/examples\r\n",
        "import os\r\n",
        "os.environ['PYTHONPATH'] = \"/env/python:/content/drive/MyDrive/00_work/004_pose_estimation/probreg/examples\"\r\n",
        "from timeit import default_timer as timer\r\n",
        "import numpy as np\r\n",
        "import open3d as o3\r\n",
        "import utils\r\n",
        "from probreg import cpd\r\n",
        "from probreg import l2dist_regs\r\n",
        "from probreg import gmmtree\r\n",
        "from probreg import filterreg\r\n",
        "import open3d\r\n",
        "threshold = 0.001\r\n",
        "max_iteration = 100"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnK1NC2rTvU3",
        "outputId": "89ed6ee3-34f5-47bc-e2eb-4062e4ca781b"
      },
      "source": [
        "bo='/content/drive/MyDrive/00_work/004_pose_estimation/probreg/result/'\r\n",
        "bp='/content/drive/MyDrive/00_work/004_pose_estimation/contextdesc/imgs/'\r\n",
        "source_r = o3.io.read_point_cloud(f'{bp}pcd_mask_cam0.ply')\r\n",
        "target_r = o3.io.read_point_cloud(f'{bp}pcd_mask_cam1.ply')\r\n",
        "source,target=get_key_ply(aug_match,cv_kpts_list[0],cv_kpts_list[1],imgdic)\r\n",
        "source_pt = cp.asarray(source.points, dtype=cp.float32)\r\n",
        "target_pt = cp.asarray(target.points, dtype=cp.float32)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:160: RuntimeWarning: invalid value encountered in reduce\n",
            "  ret = umr_sum(arr, axis, dtype, out, keepdims)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbVXE9-6TX1E",
        "outputId": "f50ec512-1c40-43c1-8c92-6d77609f3f39"
      },
      "source": [
        "res_icp = o3.registration.registration_icp(source, target, 20,\r\n",
        "                                       np.identity(4), o3.registration.TransformationEstimationPointToPoint(),\r\n",
        "                                       o3.registration.ICPConvergenceCriteria(max_iteration=max_iteration))\r\n",
        "ply=source_r.transform(res_icp.transformation)\r\n",
        "open3d.io.write_point_cloud(f'{bo}feat_pcd_merge_cam01_probreg.aug_match.s.icp.ply', ply)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CogwjszQN-1",
        "outputId": "10f0baf1-6acc-4985-e20d-3ab46c13d679"
      },
      "source": [
        "res_cpd = cpd.registration_cpd(source, target, maxiter=max_iteration, tol=threshold)\r\n",
        "r=res_cpd.transformation.rot\r\n",
        "t=res_cpd.transformation.t\r\n",
        "trans=generateTransMatrixRt(t,r)\r\n",
        "ply=source_r.transform(res_icp.transformation)\r\n",
        "open3d.io.write_point_cloud(f'{bo}feat_pcd_merge_cam01_probreg.aug_match.s.cpd.ply', ply)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kJzJfBKQhh4",
        "outputId": "23a56971-4874-4d04-93aa-731a0e19e139"
      },
      "source": [
        "res_svr = l2dist_regs.registration_svr(source, target, opt_maxiter=max_iteration, opt_tol=threshold)\r\n",
        "r=res_svr.rot\r\n",
        "t=res_svr.t\r\n",
        "trans=generateTransMatrixRt(t,r)\r\n",
        "ply=source_r.transform(res_icp.transformation)\r\n",
        "open3d.io.write_point_cloud(f'{bo}feat_pcd_merge_cam01_probreg.aug_match.s.svr.ply', ply)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQiq-OdIRvZG",
        "outputId": "6696c446-370b-4560-8e91-58c544926b3b"
      },
      "source": [
        "res_gmmtree = gmmtree.registration_gmmtree(source, target, maxiter=max_iteration, tol=threshold)\r\n",
        "r=res_gmmtree.transformation.rot\r\n",
        "t=res_gmmtree.transformation.t\r\n",
        "trans=generateTransMatrixRt(t,r)\r\n",
        "ply=source_r.transform(res_icp.transformation)\r\n",
        "open3d.io.write_point_cloud(f'{bo}feat_pcd_merge_cam01_probreg.aug_match.s.gmmtree.ply', ply)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cB2cV3bXJGq",
        "outputId": "87b17f69-2426-4b91-80bb-2631ab88d59c"
      },
      "source": [
        "res_filterreg = filterreg.registration_filterreg(source, target,\r\n",
        "                                       sigma2=None, maxiter=max_iteration, tol=threshold)\r\n",
        "r=res_filterreg.transformation.rot\r\n",
        "t=res_filterreg.transformation.t\r\n",
        "trans=generateTransMatrixRt(t,r)\r\n",
        "ply=source_r.transform(res_icp.transformation)\r\n",
        "open3d.io.write_point_cloud(f'{bo}feat_pcd_merge_cam01_probreg.aug_match.s..filterreg.ply', ply)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdo9IaGebBa-",
        "outputId": "65461681-5edb-48af-cb4b-7560fce802a4"
      },
      "source": [
        ""
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqdbLjDyGev5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuXBy51FTlxX"
      },
      "source": [
        "# !pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKvhhvKZPvwV"
      },
      "source": [
        "# %cd /content/lf-net-release\r\n",
        "# !python run_lfnet.py \\\r\n",
        "#   --in_dir=/content/lf-net-release/samples \\\r\n",
        "#   --out_dir=/content/lf-net-release/dump_feats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPk5LvcH_HEi"
      },
      "source": [
        "# %cd /content/lf-net-release/models\r\n",
        "# !pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0rvXC4S-uoe"
      },
      "source": [
        "# img_name = 'london_bridge-00001.jpg'\r\n",
        "# img_path = '../samples/'+img_name\r\n",
        "# kp_path = '../dump_feats/{}.npz'.format(img_name)\r\n",
        "# image = imread(img_path).astype(np.float32) / 255\r\n",
        "# kp_info = np.load(kp_path)\r\n",
        "# kpts = kp_info['kpts']\r\n",
        "# feats = kp_info['descs']\r\n",
        "# height, width = kp_info['size']\r\n",
        "# image = cv2.resize(image, (width, height))\r\n",
        "\r\n",
        "# print('Load {}-kpts, feat={}-D imsize={}x{}'.format(kpts.shape[0], feats.shape[1], width, height))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8segQoaJHpb"
      },
      "source": [
        "# def get_kpt_desc(img_name):\r\n",
        "#   # img_name = 'london_bridge-00001.jpg'\r\n",
        "#   img_path = '../samples/'+img_name\r\n",
        "#   kp_path = '../dump_feats/{}.npz'.format(img_name)\r\n",
        "#   image = imread(img_path).astype(np.float32) / 255\r\n",
        "#   kp_info = np.load(kp_path)\r\n",
        "#   kpts = kp_info['kpts']\r\n",
        "#   feats = kp_info['descs']\r\n",
        "#   height, width = kp_info['size']\r\n",
        "#   image = cv2.resize(image, (width, height))\r\n",
        "#   return kpts,feats,image\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_1P0MuVI19u"
      },
      "source": [
        "# def get_good_match_knn(bf,desc1,desc2):\r\n",
        "#     # マッチング器を作成する。\r\n",
        "#     matches = bf.knnMatch(desc1, desc2, k=2)\r\n",
        "#     # レシオテストを行う。\r\n",
        "#     good_matches = []\r\n",
        "#     thresh = 0.3\r\n",
        "#     for first, second in matches:\r\n",
        "#         if first.distance < second.distance * thresh:\r\n",
        "#             good_matches.append(first)\r\n",
        "#     print(\"good_matches:\",len(good_matches))\r\n",
        "#     return good_matches\r\n",
        "# kpts1,desc1,img1= get_kpt_desc('london_bridge-00001.jpg')\r\n",
        "# kpts2,desc2,img2=get_kpt_desc('london_bridge-00002.jpg')\r\n",
        "# bf = cv2.BFMatcher(cv2.NORM_HAMMING)\r\n",
        "# good_matches=get_good_match(bf,desc1,desc2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}